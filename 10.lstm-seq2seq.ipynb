{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k1Hc3INaAv_M"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import warnings\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "from tqdm import tqdm\n",
        "sns.set()\n",
        "tf.compat.v1.random.set_random_seed(1234)"
      ],
      "metadata": {
        "id": "CZFyKt5E7hut"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('C:\\Users\\Anderson\\AppData\\Local\\Programs\\Python\\dataset\\GOOG-year.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "UdWlyMPiD6W3",
        "outputId": "5a57939c-ebbf-4b68-89df-5f4a534ebe82"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-84-8bcdb148cf74>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df = pd.read_csv('C:\\Users\\Anderson\\AppData\\Local\\Programs\\Python\\dataset\\GOOG-year.csv')\u001b[0m\n\u001b[0m                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('C:\\Users\\Anderson\\AppData\\Local\\Programs\\Python\\dataset\\GOOG-year.csv')\n",
        "minmax = MinMaxScaler().fit(df.iloc[:, 4:5].astype('float32')) # Close index\n",
        "df_log = minmax.transform(df.iloc[:, 4:5].astype('float32')) # Close index\n",
        "df_log = pd.DataFrame(df_log)\n",
        "df_log.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "I0q5SU7KFp5l",
        "outputId": "5e4daeba-1721-4e10-8991-04cb66511943"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-90-c30ff179db40>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df = pd.read_csv('C:\\Users\\Anderson\\AppData\\Local\\Programs\\Python\\dataset\\GOOG-year.csv')\u001b[0m\n\u001b[0m                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 30\n",
        "simulation_size = 10\n",
        "\n",
        "df = pd.read_csv('C:\\Users\\Anderson\\AppData\\Local\\Programs\\Python\\dataset\\GOOG-year.csv')\n",
        "minmax = MinMaxScaler().fit(df.iloc[:, 4:5].astype('float32')) # Close index\n",
        "df_log = minmax.transform(df.iloc[:, 4:5].astype('float32')) # Close index\n",
        "df_log = pd.DataFrame(df_log)\n",
        "df_train = df_log.iloc[:-test_size]\n",
        "df_test = df_log.iloc[-test_size:]\n",
        "df.shape, df_train.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "ZTBznsbnIeWd",
        "outputId": "5558c27a-001e-4384-aba1-f5ab9f51107b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-91-d2870666fb60>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    df = pd.read_csv('C:\\Users\\Anderson\\AppData\\Local\\Programs\\Python\\dataset\\GOOG-year.csv')\u001b[0m\n\u001b[0m                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "    def __init__(\n",
        "        self,\n",
        "        learning_rate,\n",
        "        num_layers,\n",
        "        size,\n",
        "        size_layer,\n",
        "        output_size,\n",
        "        forget_bias = 0.1,\n",
        "    ):\n",
        "        def lstm_cell(size_layer):\n",
        "            return tf.nn.rnn_cell.LSTMCell(size_layer, state_is_tuple = False)\n",
        "\n",
        "        rnn_cells = tf.nn.rnn_cell.MultiRNNCell(\n",
        "            [lstm_cell(size_layer) for _ in range(num_layers)],\n",
        "            state_is_tuple = False,\n",
        "        )\n",
        "        self.X = tf.placeholder(tf.float32, (None, None, size))\n",
        "        self.Y = tf.placeholder(tf.float32, (None, output_size))\n",
        "        drop = tf.contrib.rnn.DropoutWrapper(\n",
        "            rnn_cells, output_keep_prob = forget_bias\n",
        "        )\n",
        "        self.hidden_layer = tf.placeholder(\n",
        "            tf.float32, (None, num_layers * 2 * size_layer)\n",
        "        )\n",
        "        _, last_state = tf.nn.dynamic_rnn(\n",
        "            drop, self.X, initial_state = self.hidden_layer, dtype = tf.float32\n",
        "        )\n",
        "        with tf.variable_scope('decoder', reuse = False):\n",
        "            rnn_cells_dec = tf.nn.rnn_cell.MultiRNNCell(\n",
        "                [lstm_cell(size_layer) for _ in range(num_layers)], state_is_tuple = False\n",
        "            )\n",
        "            drop_dec = tf.contrib.rnn.DropoutWrapper(\n",
        "                rnn_cells_dec, output_keep_prob = forget_bias\n",
        "            )\n",
        "            self.outputs, self.last_state = tf.nn.dynamic_rnn(\n",
        "                drop_dec, self.X, initial_state = last_state, dtype = tf.float32\n",
        "            )\n",
        "\n",
        "        self.logits = tf.layers.dense(self.outputs[-1], output_size)\n",
        "        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(\n",
        "            self.cost\n",
        "        )\n",
        "\n",
        "def calculate_accuracy(real, predict):\n",
        "    real = np.array(real) + 1\n",
        "    predict = np.array(predict) + 1\n",
        "    percentage = 1 - np.sqrt(np.mean(np.square((real - predict) / real)))\n",
        "    return percentage * 100\n",
        "def anchor(signal, weight):\n",
        "    buffer = []\n",
        "    last = signal[0]\n",
        "    for i in signal:\n",
        "        smoothed_val = last * weight + (1 - weight) * i\n",
        "        buffer.append(smoothed_val)\n",
        "        last = smoothed_val\n",
        "    return buffer"
      ],
      "metadata": {
        "id": "W2BVWPX9IwU9"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 1\n",
        "size_layer = 128\n",
        "timestamp = 5\n",
        "epoch = 300\n",
        "dropout_rate = 0.8\n",
        "future_day = test_size\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "BtifzPKJI6c8"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forecast():\n",
        "    tf.reset_default_graph()\n",
        "    modelnn = Model(\n",
        "        learning_rate, num_layers, df_log.shape[1], size_layer, df_log.shape[1], dropout_rate\n",
        "    )\n",
        "    sess = tf.InteractiveSession()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    date_ori = pd.to_datetime(df.iloc[:, 0]).tolist()\n",
        "\n",
        "    pbar = tqdm(range(epoch), desc = 'train loop')\n",
        "    for i in pbar:\n",
        "        init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
        "        total_loss, total_acc = [], []\n",
        "        for k in range(0, df_train.shape[0] - 1, timestamp):\n",
        "            index = min(k + timestamp, df_train.shape[0] - 1)\n",
        "            batch_x = np.expand_dims(\n",
        "                df_train.iloc[k : index, :].values, axis = 0\n",
        "            )\n",
        "            batch_y = df_train.iloc[k + 1 : index + 1, :].values\n",
        "            logits, last_state, _, loss = sess.run(\n",
        "                [modelnn.logits, modelnn.last_state, modelnn.optimizer, modelnn.cost],\n",
        "                feed_dict = {\n",
        "                    modelnn.X: batch_x,\n",
        "                    modelnn.Y: batch_y,\n",
        "                    modelnn.hidden_layer: init_value,\n",
        "                },\n",
        "            )\n",
        "            init_value = last_state\n",
        "            total_loss.append(loss)\n",
        "            total_acc.append(calculate_accuracy(batch_y[:, 0], logits[:, 0]))\n",
        "        pbar.set_postfix(cost = np.mean(total_loss), acc = np.mean(total_acc))\n",
        "\n",
        "    future_day = test_size\n",
        "\n",
        "    output_predict = np.zeros((df_train.shape[0] + future_day, df_train.shape[1]))\n",
        "    output_predict[0] = df_train.iloc[0]\n",
        "    upper_b = (df_train.shape[0] // timestamp) * timestamp\n",
        "    init_value = np.zeros((1, num_layers * 2 * size_layer))\n",
        "\n",
        "    for k in range(0, (df_train.shape[0] // timestamp) * timestamp, timestamp):\n",
        "        out_logits, last_state = sess.run(\n",
        "            [modelnn.logits, modelnn.last_state],\n",
        "            feed_dict = {\n",
        "                modelnn.X: np.expand_dims(\n",
        "                    df_train.iloc[k : k + timestamp], axis = 0\n",
        "                ),\n",
        "                modelnn.hidden_layer: init_value,\n",
        "            },\n",
        "        )\n",
        "        init_value = last_state\n",
        "        output_predict[k + 1 : k + timestamp + 1] = out_logits\n",
        "\n",
        "    if upper_b != df_train.shape[0]:\n",
        "        out_logits, last_state = sess.run(\n",
        "            [modelnn.logits, modelnn.last_state],\n",
        "            feed_dict = {\n",
        "                modelnn.X: np.expand_dims(df_train.iloc[upper_b:], axis = 0),\n",
        "                modelnn.hidden_layer: init_value,\n",
        "            },\n",
        "        )\n",
        "        output_predict[upper_b + 1 : df_train.shape[0] + 1] = out_logits\n",
        "        future_day -= 1\n",
        "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
        "    init_value = last_state\n",
        "\n",
        "    for i in range(future_day):\n",
        "        o = output_predict[-future_day - timestamp + i:-future_day + i]\n",
        "        out_logits, last_state = sess.run(\n",
        "            [modelnn.logits, modelnn.last_state],\n",
        "            feed_dict = {\n",
        "                modelnn.X: np.expand_dims(o, axis = 0),\n",
        "                modelnn.hidden_layer: init_value,\n",
        "            },\n",
        "        )\n",
        "        init_value = last_state\n",
        "        output_predict[-future_day + i] = out_logits[-1]\n",
        "        date_ori.append(date_ori[-1] + timedelta(days = 1))\n",
        "\n",
        "    output_predict = minmax.inverse_transform(output_predict)\n",
        "    deep_future = anchor(output_predict[:, 0], 0.3)\n",
        "\n",
        "    return deep_future[-test_size:]"
      ],
      "metadata": {
        "id": "IiOev2gYI7kM"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for i in range(simulation_size):\n",
        "    print('simulation %d'%(i + 1))\n",
        "    results.append(forecast())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "czBDKoJzJOWr",
        "outputId": "1e6c2db0-796f-4cc1-b0d6-2fa515673ddf"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simulation 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-104-f5aa569f2292>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'simulation %d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-100-ddb3f8b7435f>\u001b[0m in \u001b[0;36mforecast\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     modelnn = Model(\n\u001b[1;32m      4\u001b[0m         \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = [calculate_accuracy(df['Close'].iloc[-test_size:].values, r) for r in results]\n",
        "\n",
        "plt.figure(figsize = (15, 5))\n",
        "for no, r in enumerate(results):\n",
        "    plt.plot(r, label = 'forecast %d'%(no + 1))\n",
        "plt.plot(df['Close'].iloc[-test_size:].values, label = 'true trend', c = 'black')\n",
        "plt.legend()\n",
        "plt.title('average accuracy: %.4f'%(np.mean(accuracies)))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "JL4lzUmhJdFP",
        "outputId": "c134db4c-c31f-4056-e797-971989e8f406"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-bece89ad4cea>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'forecast %d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'true trend'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'average accuracy: %.4f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}